{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RekXkRcj9UB"
      },
      "source": [
        "# Introduction to Artificial Intelligence/Machine Learning\n",
        "By Josh McGiff - IGNITE - ISE 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "QsGzNg-NVJz9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9W7jcwvJFwn"
      },
      "source": [
        "## Upload files to be used for building a classification model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P6giXswnFtN"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2_y5-GfIHOF"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload the zip file from your local machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgzUwy-7IKmF"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Assuming there's only one zip file uploaded, get its file name\n",
        "zip_filename = next(iter(uploaded))\n",
        "\n",
        "# Set the extraction path\n",
        "extraction_path = \"/content/photos\"\n",
        "\n",
        "# Ensure the extraction path directory exists\n",
        "if not os.path.exists(extraction_path):\n",
        "    os.makedirs(extraction_path)\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "print(f\"Extracted files to {extraction_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The number AND QUALITY (are they representative?) of images used to train the model has a considerable impact on the performance of the model."
      ],
      "metadata": {
        "id": "odAFb_nNo669"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoH-J_ZYJQQR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define directories\n",
        "extraction_path = \"/content/photos/Photos\"\n",
        "train_dir = os.path.join(extraction_path, 'train')\n",
        "val_dir = os.path.join(extraction_path, 'validation')\n",
        "test_dir = os.path.join(extraction_path, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Define class directories\n",
        "class_a_dir = os.path.join(extraction_path, 'A')\n",
        "class_b_dir = os.path.join(extraction_path, 'B')\n",
        "os.makedirs(os.path.join(train_dir, 'A'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'B'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'A'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'B'), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, 'A'), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, 'B'), exist_ok=True)\n",
        "\n",
        "# Function to split data\n",
        "def split_data(source, train_dir, validation_dir, test_dir, train_size=0.7, val_size=0.2):\n",
        "    files = [os.path.join(source, f) for f in os.listdir(source) if os.path.isfile(os.path.join(source, f))]\n",
        "    train_files, temp_files = train_test_split(files, train_size=train_size)\n",
        "    val_files, test_files = train_test_split(temp_files, test_size=(1 - val_size - train_size))\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy(f, train_dir)\n",
        "    for f in val_files:\n",
        "        shutil.copy(f, validation_dir)\n",
        "    for f in test_files:\n",
        "        shutil.copy(f, test_dir)\n",
        "\n",
        "# Apply the function to both classes\n",
        "split_data(class_a_dir, os.path.join(train_dir, 'A'), os.path.join(val_dir, 'A'), os.path.join(test_dir, 'A'))\n",
        "split_data(class_b_dir, os.path.join(train_dir, 'B'), os.path.join(val_dir, 'B'), os.path.join(test_dir, 'B'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size is considered a hyperparameter as it determines how often weight updates are done.\n",
        "\n",
        "## ***TODO: Play around with the sliders below to find the best performance!***"
      ],
      "metadata": {
        "id": "ltsTizKmq02c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn-u2_8YMoD9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Create an input widget for batch size\n",
        "batch_size_widget = widgets.IntText(\n",
        "    value=20,  # Default batch size\n",
        "    description='Batch Size:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "\n",
        "# Function to update batch size and recompile generators\n",
        "def update_generators(batch_size):\n",
        "    # Data Generators\n",
        "    global train_generator\n",
        "    global validation_generator\n",
        "    global test_generator\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Flow from directory with new batch size\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        os.path.join(train_dir),\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        os.path.join(val_dir),\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        os.path.join(test_dir),\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"Batch size set to: {batch_size}\")\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "\n",
        "# Callback function to link the widget value with the generators\n",
        "def on_batch_size_change(change):\n",
        "    update_generators(batch_size_widget.value)\n",
        "\n",
        "# Set up a listener for changes in the widget\n",
        "batch_size_widget.observe(on_batch_size_change, names='value')\n",
        "\n",
        "# Display the input widget\n",
        "display(batch_size_widget)\n",
        "\n",
        "# Initially compile generators with the default batch size\n",
        "train_gen, test_gen, validate_gen = update_generators(batch_size_widget.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_gen)"
      ],
      "metadata": {
        "id": "KL4YvB7-YSeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the model architecture"
      ],
      "metadata": {
        "id": "TZgjLGjwVel3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code for building the VGG-like CNN model -- The what? -> VGG is a specific type of model architecture and CNN stands for convolutional neural network -> uses convolutional approach (kernal)"
      ],
      "metadata": {
        "id": "AJJuuGeprX7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# First convolutional layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third convolutional layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Fourth convolutional layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output and pass it through Dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n"
      ],
      "metadata": {
        "id": "0Kh1WMFGcOsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following section has a load of boilerplate/ugly code that is there to create interactable visual elements for tuning hyperparameters.\n",
        "\n",
        "This section is responsible for defining the optimiser and the learning rate, two hyperparameters that impact the performance of the model. Remember how we mentioned that a machine learning model needs to learn a certain function by updating weights? Well this is an optimisation problem: **what set of weights/values give us the best model performance.** We want to MINIMISE the loss function - apologies as this statement might trigger LC Maths/AP Maths, but for good reason! Finally a use for calculus!!\n",
        "\n",
        "The learning rate just defines how much the weights are updated.\n",
        "\n",
        "Don't worry if this makes little sense, it is a lot, and just intended to give a taster of AI/ML\n",
        "\n",
        "## ***TODO: Play around with the sliders below to find the best performance!***"
      ],
      "metadata": {
        "id": "uYHwNzWlwX_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers, models, layers\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Dropdown for selecting optimizer\n",
        "optimizer_dropdown = widgets.Dropdown(\n",
        "    options=['adam', 'sgd', 'rmsprop', 'adagrad'],\n",
        "    value='adam',\n",
        "    description='Optimizer:',\n",
        ")\n",
        "\n",
        "# Slider for selecting learning rate\n",
        "lr_slider = widgets.FloatSlider(\n",
        "    value=0.001,\n",
        "    min=0.00001,\n",
        "    max=1.0,\n",
        "    step=0.0001,\n",
        "    description='Learning Rate:',\n",
        "    readout_format='.5f'\n",
        ")\n",
        "\n",
        "# Function to update the optimizer based on user selection\n",
        "def update_optimizer(optimizer_name, learning_rate):\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'sgd':\n",
        "        optimizer = optimizers.SGD(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'adagrad':\n",
        "        optimizer = optimizers.Adagrad(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(f'Compiled with optimizer: {optimizer_name}, Learning rate: {learning_rate}')\n",
        "\n",
        "# Function to link dropdown and slider to the compile function\n",
        "def on_change(change):\n",
        "    update_optimizer(optimizer_dropdown.value, lr_slider.value)\n",
        "\n",
        "# Link changes in dropdown and slider to update the model\n",
        "optimizer_dropdown.observe(on_change, names='value')\n",
        "lr_slider.observe(on_change, names='value')\n",
        "\n",
        "# Display the widgets\n",
        "display(optimizer_dropdown, lr_slider)\n",
        "\n",
        "# Initially compile the model with default values\n",
        "update_optimizer(optimizer_dropdown.value, lr_slider.value)\n"
      ],
      "metadata": {
        "id": "P_tf64orcUH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is where the model is actually trained. model.fit() does this.\n",
        "\n",
        "However, model.fit() can take in many arguments/parameters:\n",
        "An epoch is one full training loop through the entire input dataset.\n",
        "Steps_per_epoch is defining the number of batches in an epoch - usually its `training data / batches` from before -> that's a hint.\n",
        "validation_steps is the same thing -> previous hint applies.\n",
        "\n",
        "## ***TODO: Play around with the widgets below to find the best hyperparameters!***\n",
        "\n",
        "** NB: Make sure to press the **Train Model** button otherwise the \"history does not exist\" error will appear!! **"
      ],
      "metadata": {
        "id": "Bp4UjT9SwWfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "# Create widgets\n",
        "epochs_widget = widgets.IntText(value=5, description='Epochs:')\n",
        "steps_per_epoch_widget = widgets.IntText(value=2, description='Steps/epoch:')\n",
        "validation_steps_widget = widgets.IntText(value=5, description='Validation steps:')\n",
        "\n",
        "# Display widgets\n",
        "display(epochs_widget, steps_per_epoch_widget, validation_steps_widget)\n",
        "history = None  # Initialize history\n",
        "\n",
        "# Function to trigger model training with parameters\n",
        "def train_model(epochs, steps_per_epoch, validation_steps):\n",
        "    # Train the model using parameters\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=validate_gen,\n",
        "        validation_steps=validation_steps\n",
        "    )\n",
        "    print(f\"Training completed: {epochs} epochs, {steps_per_epoch} steps per epoch, {validation_steps} validation steps.\")\n",
        "    return history  # Return history object\n",
        "\n",
        "# Create a button to start training\n",
        "train_button = widgets.Button(description=\"Train Model\")\n",
        "\n",
        "# Function to handle button click and start training\n",
        "def on_button_click(b):\n",
        "    # Retrieve widget values and pass them as parameters\n",
        "    epochs = epochs_widget.value\n",
        "    steps_per_epoch = steps_per_epoch_widget.value\n",
        "    validation_steps = validation_steps_widget.value\n",
        "\n",
        "    global history  # Declare global history to store it\n",
        "    history = train_model(epochs, steps_per_epoch, validation_steps)  # Call train_model with parameters\n",
        "\n",
        "# Link button click event to the function\n",
        "train_button.on_click(on_button_click)\n",
        "\n",
        "# Display the button\n",
        "display(train_button)\n"
      ],
      "metadata": {
        "id": "t_6N2Qu2cVj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model's performance"
      ],
      "metadata": {
        "id": "x5oaiopeXDDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are some types of graphs detailing the accuracy/loss of the training/validation sets."
      ],
      "metadata": {
        "id": "1chWMbNr2ZzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# Plot Accuracy and Loss\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2F94NqazlNzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything up until now has resulted in us building a model! But we always to evaluate the model on a test set, in order to qualify whether it is good or not.\n",
        "\n",
        "The following section evaluates the model by inputting unseen data to see if it gets the predicitons right or not. It's like a final exam, testing whether after all the study, has the model learned anything or did it just rote learn the data it saw before.\n",
        "\n",
        "The big chess board-looking diagram is called a Confusion Matrix and it highlights how often it predicted correctly/incorrectly.\n"
      ],
      "metadata": {
        "id": "M4DKl1EY1one"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ROC curves essentially reveal how well the model performs in comparison with a random guess."
      ],
      "metadata": {
        "id": "yCQaG347asK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# Evaluation on Test Set\n",
        "test_generator.reset()\n",
        "y_pred = model.predict(test_generator, steps=test_generator.n // test_generator.batch_size + 1)\n",
        "y_pred = np.round(y_pred).flatten()  # Assuming binary classification\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Pretty Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n",
        "\n",
        "# ROC AUC Score\n",
        "print('\\nROC AUC Score:')\n",
        "print(roc_auc_score(y_true, y_pred))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_score(y_true, y_pred):.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y6vyIdkik7wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with any image"
      ],
      "metadata": {
        "id": "VNNk_JI0XNVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can upload any image and see how well it fairs! Why not upload an image of a completely random person and see who it is predicted to be out of A and B"
      ],
      "metadata": {
        "id": "rKaZlcww2xmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def upload_and_predict():\n",
        "    uploaded = files.upload()  # Allow students to upload an image file\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        path = '/content/' + fn\n",
        "        img = image.load_img(path, target_size=(150, 150))  # Load and resize the image\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x / 255.0  # Rescale the image\n",
        "\n",
        "        # Display the image\n",
        "        display(image.load_img(path))\n",
        "\n",
        "        # Predicting with the model\n",
        "        prediction = model.predict(x)\n",
        "        if prediction[0] > 0.5:\n",
        "            print(\"The image is classified as: Person B (Yourself)\")\n",
        "        else:\n",
        "            print(\"The image is classified as: Person A (Charli xcx)\")\n",
        "\n",
        "        # Optionally, you could also return the prediction if you want to use it further\n",
        "        return prediction\n",
        "\n",
        "# Call the function to upload and predict\n",
        "upload_and_predict()\n"
      ],
      "metadata": {
        "id": "NIhzNZObdWXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🥳🥳 Congratulations you just built your first machine learning AI model!! 🥳🥳\n",
        "\n",
        "That's earlier on in your undergrad than when I did it, all those years (2) ago 👴!"
      ],
      "metadata": {
        "id": "6umE1tT227D9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}